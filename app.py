import streamlit as st
import speech_recognition as sr
from streamlit_mic_recorder import mic_recorder
from io import BytesIO
import edge_tts
import asyncio
import os
import random
import pandas as pd
from groq import Groq # ğŸ‘ˆ æ”¹ç”¨ Groq
import re

# --- è¨­å®šå€ ---
DEFAULT_API_KEY = "" 
EXCEL_FILE = "Questions.xlsx"

# --- ğŸ’… CSS ç¾åŒ–æ¨£å¼ ---
def load_custom_css():
    st.markdown("""
    <style>
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        .question-card {
            background-color: #f0f2f6;
            border-left: 5px solid #ff4b4b;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
        }
        .question-text {
            font-size: 24px;
            font-weight: bold;
            color: #1f1f1f;
        }
        .user-answer-box {
            background-color: #e8f4f9;
            border: 1px solid #d1e7ef;
            padding: 15px;
            border-radius: 10px;
            color: #0c5460;
            font-style: italic;
            margin-bottom: 20px;
        }
        .stButton button {
            height: 44px;
        }
    </style>
    """, unsafe_allow_html=True)

# --- æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

def load_questions_from_excel(file_path):
    try:
        df = pd.read_excel(file_path)
        if 'Question' in df.columns:
            return df['Question'].dropna().astype(str).tolist()
        return []
    except:
        return []

def transcribe_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(BytesIO(audio_bytes)) as source:
            audio_data = r.record(source)
            text = r.recognize_google(audio_data, language='en-US')
            return text
    except:
        return None

# ğŸ‘‡ [é‡é»ä¿®æ”¹] é€™è£¡æ”¹æˆå‘¼å« Groq API
def get_ai_feedback(api_key, question, user_text):
    try:
        client = Groq(api_key=api_key)
        
        # System Prompt: è¨­å®š AI çš„è§’è‰²
        system_prompt = """
        Act as a strict IELTS speaking examiner.
        Evaluate the user's answer based on 4 criteria (0-100).
        Provide feedback in the exact requested format.
        """

        # User Prompt: å‚³å…¥é¡Œç›®èˆ‡å›ç­”
        user_prompt = f"""
        Topic: "{question}"
        User Answer: "{user_text}"
        
        Please output the response in this exact format:
        
        [SCORES]
        Fluency: <score>
        Vocabulary: <score>
        Grammar: <score>
        Pronunciation: <score>
        [/SCORES]

        ### ğŸ“ Detailed Feedback
        (Provide bullet points for each criteria here)

        ### ğŸ’¡ Better Expression
        (One perfect native sentence)

        ### ğŸ”§ Advice (Traditional Chinese)
        (One key tip)
        """

        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile", # ğŸ‘ˆ ä½¿ç”¨ Groq ä¸Šå¼·å¤§çš„ Llama 3.3 æ¨¡å‹
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3, # é™ä½éš¨æ©Ÿæ€§ï¼Œè®“æ ¼å¼æ›´ç©©å®š
            max_tokens=1024
        )
        
        return completion.choices[0].message.content

    except Exception as e:
        return f"âš ï¸ Groq API Error: {e}"

def parse_scores(text):
    scores = {"Fluency": 0, "Vocabulary": 0, "Grammar": 0, "Pronunciation": 0}
    try:
        pattern = r"(\w+):\s*(\d+)"
        matches = re.findall(pattern, text)
        for key, value in matches:
            if key in scores:
                scores[key] = int(value)
    except:
        pass
    return scores

async def _edge_tts_save(text, filename):
    communicate = edge_tts.Communicate(text, "en-US-AndrewNeural")
    await communicate.save(filename)

def play_tts(text):
    temp_file = "temp_feedback.mp3"
    asyncio.run(_edge_tts_save(text, temp_file))
    st.audio(temp_file)

# --- é é¢ä¸»ç¨‹å¼ ---

st.set_page_config(page_title="Speaking Pro (Groq)", page_icon="âš¡", layout="centered")
load_custom_css()

# Sidebar
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/4712/4712009.png", width=80)
    st.title("Settings")
    # æç¤ºä½¿ç”¨è€…è¼¸å…¥ Groq Key
    api_key_input = st.text_input("ğŸ”‘ Groq API Key", value=DEFAULT_API_KEY, type="password", help="Get it from console.groq.com")
    
    st.divider()
    if st.button("ğŸ“‚ Reload Excel Question"):
        st.session_state.questions_list = load_questions_from_excel(EXCEL_FILE)
        st.rerun()

# åˆå§‹åŒ–
if "questions_list" not in st.session_state:
    st.session_state.questions_list = load_questions_from_excel(EXCEL_FILE)
if "current_question" not in st.session_state:
    st.session_state.current_question = random.choice(st.session_state.questions_list) if st.session_state.questions_list else "No Question"
if "transcript" not in st.session_state:
    st.session_state.transcript = ""
if "feedback" not in st.session_state:
    st.session_state.feedback = ""

# --- UI ä½ˆå±€ ---

st.title("âš¡ AI Speaking Coach")
st.markdown("Powered by **Groq Llama-3** for ultra-fast feedback.")

# 1. é¡Œç›®å¡ç‰‡
st.markdown(f"""
<div class="question-card">
    <div style="color: #666; font-size: 14px; margin-bottom: 5px;">CURRENT TOPIC</div>
    <div class="question-text">{st.session_state.current_question}</div>
</div>
""", unsafe_allow_html=True)

# 2. æ“ä½œæŒ‰éˆ•å€
col1, col2, col3 = st.columns([1, 2, 1], vertical_alignment="center")

with col1:
    if st.button("ğŸ² Skip Topic", use_container_width=True):
        st.session_state.current_question = random.choice(st.session_state.questions_list)
        st.session_state.transcript = ""
        st.session_state.feedback = ""
        st.rerun()

with col2:
    # é€™è£¡ä¿ç•™äº† format="wav" çš„ä¿®æ­£ï¼Œç¢ºä¿éŒ„éŸ³æ­£å¸¸
    audio_blob = mic_recorder(start_prompt="ğŸ”´ Record", stop_prompt="â¹ï¸ Stop", key='recorder', format="wav")

with col3:
    pass

# 3. è™•ç†èˆ‡é¡¯ç¤º
if audio_blob:
    with st.spinner("âš¡ Thinking at light speed..."): # æ”¹äº†æç¤ºæ–‡å­—ï¼Œå¼·èª¿ Groq çš„é€Ÿåº¦
        transcript = transcribe_audio(audio_blob['bytes'])
        if transcript:
            st.session_state.transcript = transcript
            if api_key_input:
                feedback = get_ai_feedback(api_key_input, st.session_state.current_question, transcript)
                st.session_state.feedback = feedback
            else:
                st.error("Please enter Groq API Key")
        else:
            st.warning("No speech detected. (Try speaking louder)")

# 4. çµæœå±•ç¤º
if st.session_state.transcript:
    st.divider()
    
    st.markdown(f"""
    <div class="user-answer-box">
        <b>ğŸ—£ï¸ You said:</b><br>
        {st.session_state.transcript}
    </div>
    """, unsafe_allow_html=True)

if st.session_state.feedback:
    scores = parse_scores(st.session_state.feedback)
    
    st.subheader("ğŸ“Š Performance Score")
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Fluency", f"{scores.get('Fluency', '-')}", border=True)
    m2.metric("Vocab", f"{scores.get('Vocabulary', '-')}", border=True)
    m3.metric("Grammar", f"{scores.get('Grammar', '-')}", border=True)
    m4.metric("Pronun.", f"{scores.get('Pronunciation', '-')}", border=True)

    st.markdown("---")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ Detailed Feedback", "ğŸ’¡ Better Expression", "ğŸ”§ Advice (ä¸­æ–‡)"])
    
    raw_text = st.session_state.feedback
    
    # ç°¡å–®çš„è§£æå®¹éŒ¯
    try:
        detailed_part = raw_text.split("### ğŸ“ Detailed Feedback")[1].split("### ğŸ’¡ Better Expression")[0]
        better_part = raw_text.split("### ğŸ’¡ Better Expression")[1].split("### ğŸ”§ Advice")[0]
        advice_part = raw_text.split("### ğŸ”§ Advice (Traditional Chinese)")[1]
    except:
        # å¦‚æœ Llama è¼¸å‡ºçš„æ ¼å¼ç¨å¾®è·‘æ‰ï¼Œå°±ç›´æ¥é¡¯ç¤ºåŸå§‹å…¨æ–‡ï¼Œé¿å…å ±éŒ¯
        detailed_part = raw_text
        better_part = "Content format parsing failed, please check detailed feedback tab."
        advice_part = "Please check detailed feedback tab."

    with tab1:
        st.markdown(detailed_part)
    
    with tab2:
        st.success(better_part)
        clean_better = better_part.replace("*", "").strip()
        # é¿å… TTS è®€åˆ°å¥‡æ€ªçš„éŒ¯èª¤è¨Šæ¯
        if len(clean_better) > 5 and "Parsing error" not in clean_better:
            if st.button("ğŸ”Š Listen to Native Version"):
                play_tts(clean_better)
            
    with tab3:
        st.info(advice_part)